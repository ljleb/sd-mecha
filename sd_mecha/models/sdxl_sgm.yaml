passthrough:
- conditioner.embedders.0.transformer.text_model.embeddings.position_ids
- first_stage_model

merge:
  unet:
    prefix: model.diffusion_model
    blocks:
      in0: input_blocks.0
      in3: input_blocks.3
      in6: input_blocks.6
      mid:
      - middle_block
      - time_embed
      out8:
      - output_blocks.8
      - time_embed
      - out
      in[1,2,4,5,7,8]:
      - input_blocks.*
      - time_embed
      out[0..7]:
      - output_blocks.*
      - time_embed

  txt:
    prefix: conditioner.embedders.0.transformer.text_model
    blocks:
      in0:
      - encoder.layers.0
      - embeddings
      in11:
      - encoder.layers.11
      - final_layer_norm
      in[1..10]: encoder.layers.*

  txt2:
    prefix: conditioner.embedders.1.model
    blocks:
      in0:
      - transformer.resblocks.0
      - positional_embedding
      - token_embedding
      in31:
      - transformer.resblocks.31
      - ln_final
      - text_projection
      - logit_scale
      in[1..30]: transformer.resblocks.*
